{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['property_id', 'location_id', 'page_url', 'property_type', 'price',\n",
       "       'price_bin', 'location', 'city', 'province_name', 'locality',\n",
       "       'latitude', 'longitude', 'baths', 'area', 'area_marla', 'area_sqft',\n",
       "       'purpose', 'bedrooms', 'date_added', 'year', 'month', 'day', 'agency',\n",
       "       'agent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = 'Property_with_Feature_Engineering.csv'  # Replace with the actual path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first 5 rows of the data\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property DataFrame:\n",
      "Index(['property_id', 'property_type', 'price', 'price_bin', 'area',\n",
      "       'area_marla', 'area_sqft', 'baths', 'bedrooms', 'purpose',\n",
      "       'location_id', 'date_added', 'agency_id', 'agent_id'],\n",
      "      dtype='object')\n",
      "\n",
      "Location DataFrame:\n",
      "Index(['location_id', 'city', 'province_name', 'locality', 'latitude',\n",
      "       'longitude'],\n",
      "      dtype='object')\n",
      "\n",
      "Agency DataFrame:\n",
      "Index(['agency', 'agency_id'], dtype='object')\n",
      "\n",
      "Agent DataFrame:\n",
      "Index(['agent', 'agent_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create the Property DataFrame\n",
    "property_columns = ['property_id', 'property_type', 'price', 'price_bin', 'area', \n",
    "                    'area_marla', 'area_sqft', 'baths', 'bedrooms', 'purpose', \n",
    "                    'year', 'month', 'day', 'location_id', 'agent', 'agency']\n",
    "property_df = df[property_columns].copy()\n",
    "\n",
    "# Create a date_added column by combining year, month, and day\n",
    "property_df['date_added'] = pd.to_datetime(property_df[['year', 'month', 'day']])\n",
    "property_df.drop(columns=['year', 'month', 'day'], inplace=True)\n",
    "\n",
    "# Create the Location DataFrame\n",
    "location_columns = ['location_id', 'city', 'province_name', 'locality', 'latitude', 'longitude']\n",
    "location_df = df[location_columns].drop_duplicates().copy()\n",
    "\n",
    "# Create the Agency DataFrame\n",
    "agency_df = df[['agency']].drop_duplicates().reset_index(drop=True).copy()\n",
    "agency_df['agency_id'] = agency_df.index + 1  # Create agency_id as a new primary key\n",
    "\n",
    "# Merge agency information into property_df\n",
    "property_df = pd.merge(property_df, agency_df, on='agency', how='left')\n",
    "\n",
    "# Create the Agent DataFrame\n",
    "agent_df = df[['agent']].drop_duplicates().reset_index(drop=True).copy()\n",
    "agent_df['agent_id'] = agent_df.index + 1  # Create agent_id as a new primary key\n",
    "\n",
    "# Merge agent information into property_df\n",
    "property_df = pd.merge(property_df, agent_df, on='agent', how='left')\n",
    "\n",
    "# Drop agency and agent names from property_df since we have their IDs now\n",
    "property_df.drop(columns=['agency', 'agent'], inplace=True)\n",
    "\n",
    "# Display the DataFrames for each entity\n",
    "print(\"Property DataFrame:\")\n",
    "print(property_df.columns)\n",
    "\n",
    "print(\"\\nLocation DataFrame:\")\n",
    "print(location_df.columns)\n",
    "\n",
    "print(\"\\nAgency DataFrame:\")\n",
    "print(agency_df.columns)\n",
    "\n",
    "print(\"\\nAgent DataFrame:\")\n",
    "print(agent_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables created successfully\n",
      "Data uploaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# PostgreSQL cloud database credentials\n",
    "db_config = {\n",
    "    'user': 'postgres',  # Your PostgreSQL username\n",
    "    'password': 'BestPasswordEver',  # Your PostgreSQL password\n",
    "    'host': '34.133.41.198',  # Replace with your VM/Cloud Instance IP or hostname\n",
    "    'port': '5432',  # PostgreSQL port\n",
    "    'database': 'postgres'  # Database name\n",
    "}\n",
    "\n",
    "# Create SQLAlchemy engine for PostgreSQL\n",
    "engine = create_engine(f\"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\")\n",
    "\n",
    "# Function to create the tables with relationships\n",
    "def create_tables():\n",
    "    with engine.connect() as conn:\n",
    "        # Create Location Table\n",
    "        conn.execute(text(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS location (\n",
    "            location_id SERIAL PRIMARY KEY,\n",
    "            city VARCHAR(100),\n",
    "            province_name VARCHAR(100),\n",
    "            locality VARCHAR(255),\n",
    "            latitude DECIMAL,\n",
    "            longitude DECIMAL\n",
    "        );\n",
    "        \"\"\"))\n",
    "\n",
    "        # Create Agency Table\n",
    "        conn.execute(text(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS agency (\n",
    "            agency_id SERIAL PRIMARY KEY,\n",
    "            agency_name VARCHAR(255)\n",
    "        );\n",
    "        \"\"\"))\n",
    "\n",
    "        # Create Agent Table\n",
    "        conn.execute(text(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS agent (\n",
    "            agent_id SERIAL PRIMARY KEY,\n",
    "            agent_name VARCHAR(255)\n",
    "        );\n",
    "        \"\"\"))\n",
    "\n",
    "        # Create Property Table with foreign keys\n",
    "        conn.execute(text(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS property (\n",
    "            property_id SERIAL PRIMARY KEY,\n",
    "            property_type VARCHAR(100),\n",
    "            price DECIMAL,\n",
    "            price_bin VARCHAR(50),\n",
    "            area DECIMAL,\n",
    "            area_marla DECIMAL,\n",
    "            area_sqft DECIMAL,\n",
    "            baths INT,\n",
    "            bedrooms INT,\n",
    "            purpose VARCHAR(50),\n",
    "            date_added DATE,\n",
    "            location_id INT,\n",
    "            agency_id INT,\n",
    "            agent_id INT,\n",
    "            FOREIGN KEY (location_id) REFERENCES location(location_id),\n",
    "            FOREIGN KEY (agency_id) REFERENCES agency(agency_id),\n",
    "            FOREIGN KEY (agent_id) REFERENCES agent(agent_id)\n",
    "        );\n",
    "        \"\"\"))\n",
    "\n",
    "        print(\"Tables created successfully\")\n",
    "\n",
    "# Function to upload the data\n",
    "def upload_data():\n",
    "    # Upload data into the tables\n",
    "    # 1. Insert Location Data\n",
    "    location_df.to_sql('location', engine, if_exists='append', index=False)\n",
    "    \n",
    "    # 2. Insert Agency Data\n",
    "    agency_df.to_sql('agency', engine, if_exists='append', index=False)\n",
    "    \n",
    "    # 3. Insert Agent Data\n",
    "    agent_df.to_sql('agent', engine, if_exists='append', index=False)\n",
    "    \n",
    "    # 4. Insert Property Data\n",
    "    property_df.to_sql('property', engine, if_exists='append', index=False)\n",
    "    \n",
    "    print(\"Data uploaded successfully\")\n",
    "\n",
    "# Call functions to create tables and upload data\n",
    "create_tables()\n",
    "upload_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to PostgreSQL\n",
      "   property_id property_type      price  price_bin      area  area_marla  \\\n",
      "0       347795         House  220000000  Very High   6 Kanal       120.0   \n",
      "1       482892         House   40000000  Very High   1 Kanal        20.0   \n",
      "2       555962         House    9500000        Low   9 Marla         9.0   \n",
      "3       562843         House  125000000  Very High   1 Kanal        20.0   \n",
      "4       686990         House   21000000       High  11 Marla        11.0   \n",
      "\n",
      "   area_sqft  baths  bedrooms   purpose  location_id date_added  agency_id  \\\n",
      "0   32670.12      0         0  For Sale            8 2019-07-17          1   \n",
      "1    5445.02      5         5  For Sale           48 2018-10-06          2   \n",
      "2    2450.26      0         3  For Sale           75 2019-07-03          3   \n",
      "3    5445.02      7         8  For Sale         3821 2019-04-04          4   \n",
      "4    2994.76      5         6  For Sale         3522 2019-04-04          4   \n",
      "\n",
      "   agent_id  \n",
      "0         1  \n",
      "1         2  \n",
      "2         3  \n",
      "3         4  \n",
      "4         4  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Your database credentials\n",
    "DATABASE_TYPE = 'postgresql'\n",
    "DB_USER = 'postgres'  # Your PostgreSQL username\n",
    "DB_PASSWORD = 'BestPasswordEver'  # Your PostgreSQL password\n",
    "DB_HOST = '34.133.41.198'  # External IP of your VM or database host\n",
    "DB_PORT = '5432'  # Default PostgreSQL port\n",
    "DB_NAME = 'postgres'  # Database name\n",
    "\n",
    "# Create an SQLAlchemy engine\n",
    "engine = create_engine(f'{DATABASE_TYPE}://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "# Connect to the database and verify the connection\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Connected to PostgreSQL\")\n",
    "        \n",
    "        # Fetch data from a specific table\n",
    "        table_name = 'Property'  # Change this to your actual table name\n",
    "        query = f\"SELECT * FROM {table_name}\"\n",
    "        \n",
    "        # Load data into a DataFrame\n",
    "        data = pd.read_sql(query, connection)\n",
    "\n",
    "        # Display the first few rows of the DataFrame to verify\n",
    "        print(data.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
